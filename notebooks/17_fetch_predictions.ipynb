{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1555e775-4045-409a-a2cd-b22934b5fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e2d67e-a5c7-453c-84e8-a210c608e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05248d6f-2194-48dd-a582-77cbda1ad16c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'hsfs' has no attribute 'hopsworks_udf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     get_feature_store\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timezone, timedelta\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_utc_hour_ceiled\u001b[39m():\n",
      "File \u001b[1;32mE:\\ms fall 2024\\sping 2025\\MLOPS\\sp25_taxi-main\\src\\inference.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta, timezone\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhopsworks\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks\\__init__.py:61\u001b[0m\n\u001b[0;32m     58\u001b[0m _secrets_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m _project_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m udf \u001b[38;5;241m=\u001b[39m hsfs\u001b[38;5;241m.\u001b[39mhopsworks_udf\u001b[38;5;241m.\u001b[39mudf\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhw_formatwarning\u001b[39m(message, category, filename, lineno, line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(category\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, message)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'hsfs' has no attribute 'hopsworks_udf'"
     ]
    }
   ],
   "source": [
    "import src.config as config\n",
    "from src.inference import (\n",
    "    get_feature_store\n",
    ")\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "def get_current_utc_hour_ceiled():\n",
    "    \"\"\"Get current UTC time ceiled to the next hour\"\"\"\n",
    "    current = datetime.now(timezone.utc)\n",
    "    if current.minute > 0 or current.second > 0:\n",
    "        # Ceil to next hour\n",
    "        current = current + timedelta(hours=1)\n",
    "\n",
    "    # Reset minutes, seconds, and microseconds\n",
    "    current = current.replace(minute=0, second=0, microsecond=0)\n",
    "    return current\n",
    "\n",
    "# Usage\n",
    "current_hour = get_current_utc_hour_ceiled()\n",
    "print(f\"Current UTC hour (ceiled): {current_hour}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5559a0-89e2-458d-9bbc-b1ec103659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_predictions():\n",
    "    current_date = pd.Timestamp.now(tz='Etc/UTC').ceil('h')\n",
    "\n",
    "    fs = get_feature_store()\n",
    "    fg = fs.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "        version=1\n",
    "    )\n",
    "\n",
    "    query = fg.select_all()\n",
    "    query = query.filter(fg.pickup_hour == current_hour)\n",
    "\n",
    "    return query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a3af64-b773-43a6-bb10-c9e209cc6cb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_feature_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_feature_store()\n\u001b[0;32m      2\u001b[0m fg \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mget_feature_group(\n\u001b[0;32m      3\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mFEATURE_GROUP_MODEL_PREDICTION,\n\u001b[0;32m      4\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m query \u001b[38;5;241m=\u001b[39m fg\u001b[38;5;241m.\u001b[39mselect_all()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_feature_store' is not defined"
     ]
    }
   ],
   "source": [
    "fs = get_feature_store()\n",
    "fg = fs.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "    version=1\n",
    ")\n",
    "\n",
    "query = fg.select_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6321059-d894-4f75-94c8-b4ea29bf8ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f3978-9a5d-4d97-b19a-88afcfb1d14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d03786a-90dc-425a-8e4e-3b4dca4a08fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 01:35:36,455 WARNING: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "\n",
      "2025-03-04 01:35:36,456 WARNING: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90415d0c-053a-4fba-94dd-eb6d231875bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39ea132b-5a59-44cb-b155-fa765164e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 01:35:41,764 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 01:35:41,768 INFO: Initializing external client\n",
      "2025-03-04 01:35:41,769 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Couldn't find execution engine. Try reconnecting to Hopsworks.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_hour\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m predictions \u001b[38;5;241m=\u001b[39m fetch_next_hour_predictions()\n",
      "Cell \u001b[1;32mIn[34], line 19\u001b[0m, in \u001b[0;36mfetch_next_hour_predictions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m next_date \u001b[38;5;241m=\u001b[39m next_hour \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m next_date_str \u001b[38;5;241m=\u001b[39m next_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_feature_store()\n\u001b[0;32m     20\u001b[0m fg \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mget_feature_group(\n\u001b[0;32m     21\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mFEATURE_GROUP_MODEL_PREDICTION,\n\u001b[0;32m     22\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# # First get the full day's data from Hopsworks\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# df = fg.filter(\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#     (fg.pickup_hour >= current_date) &\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Then filter for next hour in the DataFrame\u001b[39;00m\n",
      "File \u001b[1;32mE:\\ms fall 2024\\sping 2025\\MLOPS\\sp25_taxi-main\\src\\inference.py:19\u001b[0m, in \u001b[0;36mget_feature_store\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_store\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FeatureStore:\n\u001b[1;32m---> 19\u001b[0m     project \u001b[38;5;241m=\u001b[39m get_hopsworks_project()\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m project\u001b[38;5;241m.\u001b[39mget_feature_store()\n",
      "File \u001b[1;32mE:\\ms fall 2024\\sping 2025\\MLOPS\\sp25_taxi-main\\src\\inference.py:13\u001b[0m, in \u001b[0;36mget_hopsworks_project\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_hopsworks_project\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m hopsworks\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;241m.\u001b[39mProject:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hopsworks\u001b[38;5;241m.\u001b[39mlogin(\n\u001b[0;32m     14\u001b[0m         project\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHOPSWORKS_PROJECT_NAME, api_key_value\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHOPSWORKS_API_KEY\n\u001b[0;32m     15\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks\\__init__.py:225\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(host, port, project, api_key_value, api_key_file, hostname_verification, trust_store_path, engine)\u001b[0m\n\u001b[0;32m    223\u001b[0m _connected_project \u001b[38;5;241m=\u001b[39m _prompt_project(_hw_connection, project, is_app)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _connected_project:\n\u001b[1;32m--> 225\u001b[0m     _set_active_project(_connected_project)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLogged in to project, explore it here \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;241m+\u001b[39m _connected_project\u001b[38;5;241m.\u001b[39mget_url()\n\u001b[0;32m    229\u001b[0m )\n\u001b[0;32m    230\u001b[0m _initialize_module_apis()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks\\__init__.py:489\u001b[0m, in \u001b[0;36m_set_active_project\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    487\u001b[0m _client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _client\u001b[38;5;241m.\u001b[39m_is_external():\n\u001b[1;32m--> 489\u001b[0m     _client\u001b[38;5;241m.\u001b[39mprovide_project(project\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks_common\\client\\external.py:160\u001b[0m, in \u001b[0;36mClient.provide_project\u001b[1;34m(self, project)\u001b[0m\n\u001b[0;32m    152\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning in Spark environment with no metastore and hopsfs, initializing Spark session\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     _spark_session \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.extensions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.delta.sql.DeltaSparkSessionExtension\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.catalog.spark_catalog\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.delta.catalog.DeltaCatalog\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m--> 160\u001b[0m hopsworks_common\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mget_connection()\u001b[38;5;241m.\u001b[39m_provide_project()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks_common\\decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hopsworks_common\\connection.py:429\u001b[0m, in \u001b[0;36mConnection._provide_project\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m engine\n\u001b[1;32m--> 429\u001b[0m engine\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_api\u001b[38;5;241m.\u001b[39mget_data_science_profile_enabled():\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# load_default_configuration has to be called before using hsml\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;66;03m# but after a project is provided to client\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_serving_api\u001b[38;5;241m.\u001b[39mload_default_configuration()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\hsfs\\engine\\__init__.py:59\u001b[0m, in \u001b[0;36mget_instance\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training` engine doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support this operation. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported engines are `\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` and `\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m         )\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _engine\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find execution engine. Try reconnecting to Hopsworks.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Couldn't find execution engine. Try reconnecting to Hopsworks."
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "def fetch_next_hour_predictions():\n",
    "    # Get current UTC time and round up to next hour\n",
    "    now = datetime.now(timezone.utc)\n",
    "    next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "    # Extract components from the rounded-up time\n",
    "    year = next_hour.year\n",
    "    month = next_hour.month\n",
    "    day = next_hour.day\n",
    "    hour = next_hour.hour\n",
    "\n",
    "    # Create date strings in YYYY-MM-DD format\n",
    "    current_date = f\"{year}-{month:02d}-{day:02d}\"\n",
    "    next_date = next_hour + timedelta(days=1)\n",
    "    next_date_str = next_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    fs = get_feature_store()\n",
    "    fg = fs.get_feature_group(\n",
    "        name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "        version=1\n",
    "    )\n",
    "\n",
    "    # # First get the full day's data from Hopsworks\n",
    "    # df = fg.filter(\n",
    "    #     (fg.pickup_hour >= current_date) &\n",
    "    #     (fg.pickup_hour < next_date_str)\n",
    "    # ).read()\n",
    "\n",
    "    # Then filter for next hour in the DataFrame\n",
    "    hour_str = f\"{current_date} {hour:02d}:00\"\n",
    "    df_hour = df[df['pickup_hour'] == hour_str]\n",
    "\n",
    "    print(f\"Current UTC time: {now}\")\n",
    "    print(f\"Next hour: {next_hour}\")\n",
    "    print(f\"Querying for date range: {current_date} to {next_date_str}\")\n",
    "    print(f\"Filtering for hour: {hour_str}\")\n",
    "    print(f\"Found {len(df_hour)} records\")\n",
    "    return df_hour\n",
    "\n",
    "# Example usage:\n",
    "predictions = fetch_next_hour_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c512f98-d569-4a9f-8391-d301b1226c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now(timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5671d3-701d-4fca-bb91-a697f622239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c2c460-25c6-4c26-84e8-ae82a1fdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930b159-b4e4-4b51-acd9-0b7b167b6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC').ceil('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb7cca-beba-4017-9fa0-5ad7b6acfe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = current_date.ceil('h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e4d11-8a5a-434c-b634-bbf9edd02bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_feature_store()  \n",
    "fg = fs.get_feature_group(  \n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTION,  \n",
    "    version=1  \n",
    ")  \n",
    "query = fg.select_all() \n",
    "# query = query.filter(fg.pickup_hour >= \"2025-02-13 04:00\")\n",
    "query = query.filter(fg.pickup_hour > \"2025-02-13 05:00:00\")  \n",
    "results = query.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab34fc8-2594-4dfd-8046-fa7ede562979",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg.filter((fg.pickup_hour >= \"2025-02-13\") & (fg.pickup_hour < \"2025-02-14\")).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb732f4b-65ee-4956-87b5-c9a9c2f367b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015ad82-b0b7-42e0-b6e3-6e69550da93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_next_hour_predictions():\n",
    "    # Get current UTC time and round up to next hour\n",
    "    now = datetime.now(timezone.utc)\n",
    "    next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "    fs = get_feature_store()\n",
    "    fg = fs.get_feature_group(name=config.FEATURE_GROUP_MODEL_PREDICTION, version=1)\n",
    "\n",
    "    # Then filter for next hour in the DataFrame\n",
    "    df_hour = df[df[\"pickup_hour\"] == next_hour]\n",
    "\n",
    "    print(f\"Current UTC time: {now}\")\n",
    "    print(f\"Next hour: {next_hour}\")\n",
    "    print(f\"Found {len(df_hour)} records\")\n",
    "    return df_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42dc2b-f1b3-40a2-8610-1bed9c822355",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fetch_next_hour_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495da67-1068-41e0-9092-458c11626900",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_feature_store()\n",
    "fg = fs.get_feature_group(name=config.FEATURE_GROUP_MODEL_PREDICTION, version=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761c899-38c7-4560-9226-d41ce20811df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052c02-a072-423f-95d5-086c1ca786eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pickup_hour\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5c3e8-156e-44a5-ac8a-ccb1479a6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now(timezone.utc)\n",
    "next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "print(next_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebe046-ae58-489e-99e7-a4f27755a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"pickup_hour\"] == next_hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a1369-58b0-4ec0-8638-b4be9cae351a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa967b07-600e-4596-814e-ed9952c23ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
